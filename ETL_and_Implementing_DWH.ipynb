{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuNYlWYSVXXpLn34O6FdIz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fuenfgeld/DMA2023TeamB/blob/main/ETL_and_Implementing_DWH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Datawarehouse and transform data from source database to datawarehouse db"
      ],
      "metadata": {
        "id": "Pu_0HR4cXoUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required libraries and mounting Google Drive"
      ],
      "metadata": {
        "id": "VUKhlQZ8b04R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id2DaZNSXeby",
        "outputId": "e69e2a50-4c5d-4999-b77d-f4c0ad00076b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "from sqlite3 import Error\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining File Paths \n",
        "\n",
        "DB_SOURCE_PATH --> where Staging database resides\n",
        "\n",
        "DB_DWH_PATH --> where DWH will reside"
      ],
      "metadata": {
        "id": "Ci1E98MlcQ3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path of source database\n",
        "DB_SOURCE_PATH = f\"/content/drive/Shareddrives/DMA_2023_D/DMA2023TeamB/source_dbs/Source_covid19_Staging.db\"\n",
        "\n",
        "# path of datawarehouse\n",
        "DB_DWH_PATH = f\"/content/drive/Shareddrives/DMA_2023_D/DMA2023TeamB/source_dbs/DWH_covid19.db\""
      ],
      "metadata": {
        "id": "MIdSHhMfcwMA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Datawarehouse"
      ],
      "metadata": {
        "id": "_gSKmC1ydvIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DB(object):\n",
        "  def __init__(self, db_file):\n",
        "    self.conn = sqlite3.connect(db_file)\n",
        "    self.cur = self.conn.cursor()\n",
        "    self.__init_db()\n",
        "  \n",
        "  def __del__(self):\n",
        "      self.conn.commit()\n",
        "      self.conn.close()\n",
        "\n",
        "  def __init_db(self):\n",
        "    # sql queries to create tables in Datawarehouse \n",
        "\n",
        "#  sql query to create d_conditions table\n",
        "    create_d_conditions = \"\"\"CREATE TABLE IF NOT EXISTS d_conditions (\n",
        "                           CONDITIONS_CODE STRING PRIMARY KEY,\n",
        "                           CONDITIONS_DESCRIPTION STRING\n",
        "                       );\"\"\"\n",
        "\n",
        "#  sql query to create d_devices table\n",
        "    create_d_devices = \"\"\"CREATE TABLE IF NOT EXISTS d_devices (\n",
        "                            DEVICES_CODE STRING PRIMARY KEY,\n",
        "                            DEVICES_DESCRIPTION STRING\n",
        "                           );\"\"\"\n",
        "\n",
        "#  sql query to create d_medications table\n",
        "    create_d_medications = \"\"\"CREATE TABLE IF NOT EXISTS d_medications (\n",
        "                            MEDICATIONS_CODE STRING PRIMARY KEY,\n",
        "                            MEDICATIONS_DESCRIPTION STRING\n",
        "                           );\"\"\"\n",
        "\n",
        "#  sql query to create d_procedures table\n",
        "    create_d_procedures = \"\"\"CREATE TABLE IF NOT EXISTS d_procedures (\n",
        "                            PROCEDURES_CODE STRING PRIMARY KEY,\n",
        "                            PROCEDURES_DESCRIPTION STRING\n",
        "                           );\"\"\"\n",
        "\n",
        "#  sql query to create d_patients table\n",
        "    create_d_patients = \"\"\"CREATE TABLE IF NOT EXISTS d_patients (\n",
        "                            PATIENTS_ID STRING PRIMARY KEY,\n",
        "                            PATIENTS_BIRTHDATE DATE,\n",
        "                            PATIENTS_DEATHDATE DATE,\n",
        "                            PATIENTS_GENDER STRING\n",
        "                           );\"\"\" \n",
        "\n",
        "# sql query to create F_ANTICOVIS table\n",
        "    create_F_ANTICOVIS = \"\"\"CREATE TABLE IF NOT EXISTS F_ANTICOVIS (\n",
        "                           PATIENTS_ID STRING,\n",
        "                           CONDITIONS_CODE STRING,\n",
        "                           PROCEDURES_CODE STRING,\n",
        "                           DEVICES_CODE STRING,\n",
        "                           MEDICATIONS_CODE STRING,\n",
        "                           MEDICATION_GRADING INT DEFAULT '0', \n",
        "                           COURSE_OF_DESEASE INT DEDAULT '0',\n",
        "                           FOREIGN KEY (PATIENTS_ID)\n",
        "                              REFERENCES d_patients (PATIENTS_ID),\n",
        "                           FOREIGN KEY (CONDITIONS_CODE)\n",
        "                              REFERENCES d_conditions (CONDITIONS_CODE),\n",
        "                           FOREIGN KEY (PROCEDURES_CODE)\n",
        "                              REFERENCES d_procedures (PROCEDURES_CODE),\n",
        "                           FOREIGN KEY (DEVICES_CODE)\n",
        "                              REFERENCES d_devices(DEVICES_CODE),\n",
        "                           FOREIGN KEY (MEDICATIONS_CODE)\n",
        "                              REFERENCES d_medications (MEDICATIONS_CODE)\n",
        "                       );\"\"\"\n",
        "    create_tables =  [create_d_conditions,# conditions dimension\n",
        "                      create_d_devices,# devices dimension\n",
        "                      create_d_medications,# medications dimension\n",
        "                      create_d_procedures, # procedures dimension\n",
        "                      create_d_patients, #patients dimension\n",
        "                      create_F_ANTICOVIS #Factstable\n",
        "                      ]\n",
        "\n",
        "    if self.conn is not None:\n",
        "      for query in create_tables:\n",
        "          self.cur.execute(query)\n",
        "    else:\n",
        "      print('Connection to database failed')"
      ],
      "metadata": {
        "id": "Zz1CPX1Rd0G3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ETL/ELT (Extract, transform, load )"
      ],
      "metadata": {
        "id": "03HhV7GvlNrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# exporting queries\n",
        "class SqlQuery:\n",
        "  def __init__(self, source_table, column_names, sink_table):\n",
        "    self.source_table = source_table\n",
        "    self.column_numbers = len(column_names)\n",
        "    self.column_names = ', '.join(column_names)\n",
        "    self.sink_table = sink_table\n",
        "\n",
        "  def extract_query(self):\n",
        "    return 'SELECT ' + self.column_names + ' FROM ' + self.source_table \n",
        "\n",
        "  def load_query(self):\n",
        "    values_str = '?,' * self.column_numbers\n",
        "    # print(\"*****\", values_str, column_names, column_numbers)\n",
        "    values_str = values_str[:-1]\n",
        "    return 'INSERT OR REPLACE INTO ' + self.sink_table + ' VALUES (' + values_str + ')'\n",
        "\n",
        "    # return 'INSERT INTO ' + self.sink_table + '(' + self.column_names + ') VALUES (' + values_str + ')'\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "-Wm_tGyGlCui"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def etl(query, source_cnx, target_cnx):\n",
        "  # extract data from source db\n",
        "  source_cursor = source_cnx.cursor()\n",
        "  source_cursor.execute(query.extract_query())\n",
        "  data = source_cursor.fetchall()\n",
        "  source_cursor.close()\n",
        "\n",
        "  # load data into warehouse db\n",
        "  if data:\n",
        "    target_cursor = target_cnx.cursor()\n",
        "    target_cursor.executemany(query.load_query(), data)\n",
        "    print('data loaded to warehouse db') \n",
        "    target_cnx.commit()\n",
        "    target_cursor.close()\n",
        "  else:\n",
        "    print('data is empty')\n",
        "\n",
        "\n",
        "def etl_process(queries, target_cnx, db_source):\n",
        "  \"\"\"\n",
        "  queries: list\n",
        "        a list of queries\n",
        "  target_cnx: SQLite connection\n",
        "  db_source: str\n",
        "        path of source database      \n",
        "  \n",
        "  \"\"\"  \n",
        "  # establish source db connection\n",
        "  try:\n",
        "    source_cnx = sqlite3.connect(db_source)\n",
        "  except Error as err:\n",
        "    print(err)\n",
        "  \n",
        "  # loop through sql queries\n",
        "  for query in etl_queue:\n",
        "    etl(query, source_cnx, target_cnx)\n",
        "    \n",
        "  # close the source db connection\n",
        "  source_cnx.close()"
      ],
      "metadata": {
        "id": "oJ5OK7CNlZ-d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create Datawarehouse\n",
        "dwh_db = DB(DB_DWH_PATH)"
      ],
      "metadata": {
        "id": "0cxGY2mFleT-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # check list of tables\n",
        "target_cnx = dwh_db.conn\n",
        "dwh_cursor = target_cnx.cursor()\n",
        "dwh_cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "#dwh_cursor.execute('PRAGMA table_info(' + \"F_ANTICOVIS\" + ');')\n",
        "print(dwh_cursor.fetchall())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48ggLPBovZ31",
        "outputId": "a8a683dc-109c-4c32-b862-65924a7d3598"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('d_conditions',), ('d_devices',), ('d_medications',), ('d_procedures',), ('d_patients',), ('F_ANTICOVIS',)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BKHfPdwkndTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('starting etl')   \n",
        "# list for iteration\n",
        "etl_queue = []\n",
        "\n",
        "# d_conditions table\n",
        "conditions_columns = ['CONDITIONS_CODE', 'CONDITIONS_DESCRIPTION']\n",
        "sql_query_conditions = SqlQuery(\"S_CONDITIONS\", conditions_columns, \"d_conditions\")\n",
        "etl_queue.append(sql_query_conditions)\n",
        "\n",
        "# d_devices table\n",
        "devices_columns = ['DEVICES_CODE', 'DEVICES_DESCRIPTION']\n",
        "sql_query_devices = SqlQuery(\"S_DEVICES\", devices_columns, \"d_devices\")\n",
        "etl_queue.append(sql_query_devices)\n",
        "\n",
        "# d_medications table\n",
        "medications_columns = ['MEDICATIONS_CODE','MEDICATIONS_DESCRIPTION']\n",
        "sql_query_medications = SqlQuery(\"S_MEDICATIONS\", medications_columns, \"d_medications\")\n",
        "etl_queue.append(sql_query_medications)\n",
        "\n",
        "# d_procedures table\n",
        "procedures_columns = ['PROCEDURES_CODE', 'PROCEDURES_DESCRIPTION']\n",
        "sql_query_procedures = SqlQuery(\"S_PROCEDURES\", procedures_columns, \"d_procedures\")\n",
        "etl_queue.append(sql_query_procedures)\n",
        "\n",
        "\n",
        "# d_patients table\n",
        "patients_columns = ['PATIENTS_ID', 'PATIENTS_BIRTHDATE', 'PATIENTS_DEATHDATE', 'PATIENTS_GENDER']\n",
        "sql_query_patients = SqlQuery(\"S_PATIENTS\", patients_columns, \"d_patients\")\n",
        "etl_queue.append(sql_query_patients)\n",
        "\n",
        "\n",
        "# list for iteration\n",
        "# etl_queue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04uxBwK6n-o0",
        "outputId": "0280660d-5174-4da5-faef-5c8004d2cb7e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting etl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load form staging Database to Datawarehouse"
      ],
      "metadata": {
        "id": "jQVvt7Xzt_4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# establish connection for target database \n",
        "target_cnx = dwh_db.conn\n",
        "etl_process(etl_queue, target_cnx, DB_SOURCE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47BForxguEV-",
        "outputId": "2151fa56-51e8-4679-8358-a268075de1ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data loaded to warehouse db\n",
            "data loaded to warehouse db\n",
            "data loaded to warehouse db\n",
            "data loaded to warehouse db\n",
            "data loaded to warehouse db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "\n",
        "# selecting relevant data for Staging DB as a Facts_Table DataFrame\n",
        "connctino_to_Staging_DB = sqlite3.connect(DB_SOURCE_PATH)\n",
        "conn = connctino_to_Staging_DB\n",
        "Staging_DB_Cursor = conn.cursor()\n",
        "\n",
        "Staging_DB_Cursor.execute (\"\"\" SELECT SSS_patients.patients_ID,\n",
        "                                      SSS_conditions.conditions_code, \n",
        "                                      SSS_procedures.procedures_code, \n",
        "                                      SSS_devices.devices_code, \n",
        "                                      SSS_medications.medications_code \n",
        "                               \n",
        "                               FROM SSS_PATIENTS \n",
        "                                    LEFT JOIN SSS_CONDITIONS \n",
        "                                           ON SSS_patients.patients_ID = SSS_conditions.conditions_patient_ID\n",
        "                                    LEFT JOIN SSS_PROCEDURES \n",
        "                                           ON SSS_patients.patients_ID = SSS_procedures.procedures_patient_ID\n",
        "                                    LEFT JOIN SSS_DEVICES \n",
        "                                           ON SSS_patients.patients_ID = SSS_devices.devices_patient_ID\n",
        "                                    LEFT JOIN SSS_MEDICATIONS\n",
        "                                           ON SSS_patients.patients_ID = SSS_medications.medications_patient_ID\n",
        "                                  \"\"\")\n",
        "DF_of_Facts_Table = DataFrame(Staging_DB_Cursor.fetchall())\n",
        "\n",
        "# renaming culums in Dataframe\n",
        "DF_of_Facts_Table.columns =['patients_ID', 'conditions_code','procedures_code', 'devices_code', 'medications_code']\n",
        "# remooving duplicates from Dataframe\n",
        "DF_of_Facts_Table.drop_duplicates()\n",
        "conn.close()\n",
        "\n",
        "# creating new table columns for medication_grading and course_of_desease grading\n",
        "DF_of_Facts_Table ['medication_grading'] = '0'\n",
        "DF_of_Facts_Table ['course_of_Desease'] = '0'\n",
        "# Replacing NaN\n",
        "DF_of_Facts_Table = DF_of_Facts_Table.fillna(0)\n",
        "\n",
        "\n",
        "# defininf and implemening course_of_desease classes\n",
        "\n",
        "grades_mapping = {\n",
        "386661006: 1,\n",
        "25064002:\t1,\n",
        "36955009:\t1,\n",
        "267102003: 1,\n",
        "261352009: 1,\n",
        "43724002:\t2,\n",
        "49727002:\t2,\n",
        "267060006: 2,\n",
        "84229001:\t2,\n",
        "57676002:\t2,\n",
        "68962001:\t2,\n",
        "68235000:\t2,\n",
        "422587007: 2,\n",
        "249497008: 2,\n",
        "234466008: 3,\n",
        "132281000119108: 3,\n",
        "267036007: 3,\n",
        "233604007: 3,\n",
        "56018004:\t3,\n",
        "371908008: 3,\n",
        "706870000: 4,\n",
        "66857006:\t4,\n",
        "389087006: 4,\n",
        "86175003:\t4,\n",
        "40095003:\t4,\n",
        "271825005: 4,\n",
        "112798008: 4,\n",
        "433112001: 4,\n",
        "431182000: 4,\n",
        "67782005:\t5,\n",
        "65710008:\t5,\n",
        "84114007:\t5,\n",
        "770349000: 5,\n",
        "76571007:\t5,\n",
        "36965003:\t5,\n",
        "449071006: 5,\n",
        "26763009:\t5,\n",
        "180325003: 5,\n",
        "302497006: 5,\n",
        "\n",
        "}\n",
        "\n",
        "# Loop through all rows\n",
        "for i, row in DF_of_Facts_Table.iterrows():\n",
        "    max_grade = []    \n",
        "    # Check if any of the codes in the 'conditions_code' column is present in the grades_mapping\n",
        "    if row['conditions_code'] in grades_mapping:\n",
        "        max_grade.append(grades_mapping[row['conditions_code']])\n",
        "    # Check if any of the codes in the 'procedures_code' column is present in the grades_mapping\n",
        "    if row['procedures_code'] in grades_mapping:\n",
        "        max_grade.append(grades_mapping[row['procedures_code']])\n",
        "    # Check if any of the codes in the 'devices_code' column is present in the grades_mapping\n",
        "    if row['devices_code'] in grades_mapping:\n",
        "        max_grade.append(grades_mapping[row['devices_code']])\n",
        "    if len(max_grade) != 0:\n",
        "        DF_of_Facts_Table.at[i, 'course_of_Desease'] = max(max_grade)\n",
        "    else:\n",
        "        DF_of_Facts_Table.at[i, 'course_of_Desease'] = 0\n",
        "\n",
        "DF_of_Facts_Table.head(30)\n",
        "\n"
      ],
      "metadata": {
        "id": "F12D9iKhztFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining and implementing medication_grading.\n",
        "\n",
        "medication_grading = {\n",
        "854235:1,\n",
        "854252:1,\n",
        "854228:1,\n",
        "309362:2,\n",
        "855332:3,\n",
        "}\n",
        "\n",
        "# Loop through all rows\n",
        "for i, row in DF_of_Facts_Table.iterrows():   \n",
        "    # Check if any of the codes in the 'conditions_code' column is present in the grades_mapping\n",
        "    if row['medications_code'] in medication_grading:\n",
        "        DF_of_Facts_Table.at[i, 'medication_grading'] = medication_grading[row['medications_code']]\n",
        "\n"
      ],
      "metadata": {
        "id": "89Ef1fvCcaDn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DF_of_Facts_Table.head(30)"
      ],
      "metadata": {
        "id": "tYkEH3kNhbC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DF_of_Facts_Table\n",
        "conn = sqlite3.connect(DB_DWH_PATH)\n",
        "\n",
        "DF_of_Facts_Table.to_sql('F_ANTICOVIS',conn, if_exists = 'replace', index = False)\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "rKAw5Rbr4xse"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect(DB_DWH_PATH)\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "#cursor.execute(\"SELECT count(*) FROM F_ANTICOVIS\")\n",
        "#cursor.execute(\"\"\"DELETE FROM F_ANTICOVIS\"\"\")\n",
        "print(cursor.fetchall())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFFb3nDc48WA",
        "outputId": "62795490-a757-4dcf-c259-cc48fc5ef96c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('d_conditions',), ('d_devices',), ('d_medications',), ('d_procedures',), ('d_patients',), ('F_ANTICOVIS',)]\n"
          ]
        }
      ]
    }
  ]
}