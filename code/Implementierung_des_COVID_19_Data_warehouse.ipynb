{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMivJ7+tuVN9mK0/YKQ0HCD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fuenfgeld/DMA2023TeamB/blob/main/Implementierung_des_COVID_19_Data_warehouse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datawarehouse creation and transformation process for data from COVID-19 source database to datawarehouse db\n"
      ],
      "metadata": {
        "id": "HBzVz9Qd6pVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required libraries and mountig googledrive with scharedfolder location containig source database"
      ],
      "metadata": {
        "id": "JHgeBipY6x4V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5wEygo_K6KIr"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "from sqlite3 import Error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive to access database\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGuvXxBQ64En",
        "outputId": "0a6dbf69-fc98-4d3c-ee91-dd5e061f2589"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining input path for Data form source database and  and output data path for Datawarehouse "
      ],
      "metadata": {
        "id": "828-Phrk67I9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# type of patients\n",
        "patient_type = \"covid19\""
      ],
      "metadata": {
        "id": "-7jzAV656_B0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path of source database in shared googledrive Folder\n",
        "DB_SOURCE_PATH = f\"/content/drive/Shareddrives/DMA_2023_D/source_dbs/source_covid19_test.db\""
      ],
      "metadata": {
        "id": "MNXVHE_p7FmJ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# path of datawarehouse with Filename DWH_COVID-19_2023.db\n",
        "DB_DWH_PATH = f\"/content/drive/Shareddrives/DMA_2023_D/source_dbs/DWH_COVID-19_2023.db\""
      ],
      "metadata": {
        "id": "6q0k0MP28y2N"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Datawarehouse "
      ],
      "metadata": {
        "id": "rX601lhe7K47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DB(object):\n",
        "  def __init__(self, db_file):\n",
        "    self.conn = sqlite3.connect(db_file)\n",
        "    self.cur = self.conn.cursor()\n",
        "    self.__init_db()\n",
        "  \n",
        "  def __del__(self):\n",
        "      self.conn.commit()\n",
        "      self.conn.close()\n",
        "\n",
        "  def __init_db(self):\n",
        "    # sql queries to create tables in Datawarehouse \n",
        "\n",
        "    #  sql query to create patients_info table -> Isoliert ID, Geburts-/Todesdatum, Gender\n",
        "    create_patients_info = \"\"\"CREATE TABLE IF NOT EXISTS patients_info (\n",
        "                           Id STRING PRIMARY KEY,\n",
        "                           BIRTHDATE DATE,\n",
        "                           DEATHDATE DATE,\n",
        "                           GENDER STRING\n",
        "                       );\"\"\"\n",
        "\n",
        "    #  sql query to create disease table -> Disease Table nicht benötigt\n",
        "\n",
        "\n",
        "    # sql query to create condition table -> Encounter ex, Encounters Table nicht gebraucht, Description as Code\n",
        "    create_conditions_info = \"\"\"CREATE TABLE IF NOT EXISTS conditions_info (\n",
        "                           START DATE,\n",
        "                           STOP DATE,\n",
        "                           PATIENT STRING,\n",
        "                           CODE STRING,\n",
        "                           DESCRIPTION STRING,\n",
        "                           FOREIGN KEY (PATIENT)\n",
        "                              REFERENCES patients_info (Id) \n",
        "                       );\"\"\"\n",
        "\n",
        "    # sql query to create careplans table -> nicht benötigt\n",
        "  \n",
        "\n",
        "    # sql query to create procedures table -> encounter ex, Reduktion auf Pat.ID und SNOMED Code\n",
        "    create_procedures_info = \"\"\"CREATE TABLE IF NOT EXISTS procedures_info (\n",
        "                           DATE DATE,\n",
        "                           PATIENT STRING,\n",
        "                           CODE STRING,\n",
        "                           DESCRIPTION STRING,\n",
        "                           FOREIGN KEY (PATIENT)\n",
        "                              REFERENCES patients_info (Id) \n",
        "                       );\"\"\"\n",
        "\n",
        "    # sql query to create medications_info table -> DESCRIPTION BELASSEN, DA MULTIPLE Medikamente\n",
        "    create_medications_info = \"\"\"CREATE TABLE IF NOT EXISTS medications_info (\n",
        "                           START DATE,\n",
        "                           STOP DATE,\n",
        "                           PATIENT STRING,\n",
        "                           CODE STRING,\n",
        "                           DESCRIPTION STRING,\n",
        "                           FOREIGN KEY (PATIENT)\n",
        "                              REFERENCES patients_info (Id)   \n",
        "                       );\"\"\"\n",
        "\n",
        "    # sql query to create observations table -> Table nicht benötigt\n",
        "\n",
        "\n",
        "    # sql query to create devices table\n",
        "    create_devices_info = \"\"\"CREATE TABLE IF NOT EXISTS devices_info (\n",
        "                           START DATE,\n",
        "                           STOP DATE,\n",
        "                           PATIENT STRING,\n",
        "                           CODE STRING,\n",
        "                           DESCRIPTION STRING,\n",
        "                           FOREIGN KEY (PATIENT)\n",
        "                              REFERENCES patients_info (Id)                 \n",
        "                       );\"\"\"\n",
        "   \n",
        "   # sql query to create Imaging_studies table -> ist leer\n",
        "   # zusätzlich sollte ein immunizations table angelegt werden:\n",
        "   # sql query to create immunizations table\n",
        "    create_immunizations_info = \"\"\"CREATE TABLE IF NOT EXISTS immunizations_info (\n",
        "                           DATE DATE,\n",
        "                           ENCOUNTER STRING,\n",
        "                           PATIENT STRING,\n",
        "                           CODE STRING,\n",
        "                           DESCRIPTION STRING,\n",
        "                           FOREIGN KEY (PATIENT)\n",
        "                              REFERENCES patients_info (Id)                 \n",
        "                       );\"\"\"\n",
        "\n",
        "\n",
        "    create_tables = [create_patients_info, # patient data\n",
        "                     create_conditions_info, create_procedures_info, create_devices_info,  # symptoms and procedure data\n",
        "                     create_medications_info, # medication data\n",
        "                     create_immunizations_info # immunization data\n",
        "                     ]\n",
        "     \n",
        "\n",
        "    if self.conn is not None:\n",
        "      # self.cur.execute(f\"drop table if exists medications_info\")\n",
        "      for query in create_tables:\n",
        "          self.cur.execute(query)\n",
        "    else:\n",
        "      print('Connection to database failed')\n",
        "\n"
      ],
      "metadata": {
        "id": "VKjfLAy_7KZy"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ETL/ELT (Extract, transform, load )"
      ],
      "metadata": {
        "id": "p7JOXU047dhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# exporting queries\n",
        "class SqlQuery:\n",
        "  def __init__(self, source_table, column_names, sink_table):\n",
        "    self.source_table = source_table\n",
        "    self.column_numbers = len(column_names)\n",
        "    self.column_names = ', '.join(column_names)\n",
        "    self.sink_table = sink_table\n",
        "\n",
        "  def extract_query(self):\n",
        "    return 'SELECT ' + self.column_names + ' FROM ' + self.source_table \n",
        "\n",
        "  def load_query(self):\n",
        "    values_str = '?,' * self.column_numbers\n",
        "    # print(\"*****\", values_str, column_names, column_numbers)\n",
        "    values_str = values_str[:-1]\n",
        "    return 'INSERT OR REPLACE INTO ' + self.sink_table + ' VALUES (' + values_str + ')'\n",
        "\n",
        "    # return 'INSERT INTO ' + self.sink_table + '(' + self.column_names + ') VALUES (' + values_str + ')'\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "SH2VPVkT7hS1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def etl(query, source_cnx, target_cnx):\n",
        "  # extract data from source db\n",
        "  source_cursor = source_cnx.cursor()\n",
        "  source_cursor.execute(query.extract_query())\n",
        "  data = source_cursor.fetchall()\n",
        "  source_cursor.close()\n",
        "\n",
        "  # load data into warehouse db\n",
        "  if data:\n",
        "    target_cursor = target_cnx.cursor()\n",
        "    target_cursor.executemany(query.load_query(), data)\n",
        "    print('data loaded to warehouse db') \n",
        "    target_cnx.commit()\n",
        "    target_cursor.close()\n",
        "  else:\n",
        "    print('data is empty')\n",
        "\n",
        "\n",
        "def etl_process(queries, target_cnx, db_source):\n",
        "  \"\"\"\n",
        "  queries: list\n",
        "        a list of queries\n",
        "  target_cnx: SQLite connection\n",
        "  db_source: str\n",
        "        path of source database      \n",
        "  \n",
        "  \"\"\"  \n",
        "  # establish source db connection\n",
        "  try:\n",
        "    source_cnx = sqlite3.connect(db_source)\n",
        "  except Error as err:\n",
        "    print(err)\n",
        "  \n",
        "  # loop through sql queries\n",
        "  for query in etl_queue:\n",
        "    etl(query, source_cnx, target_cnx)\n",
        "    \n",
        "  # close the source db connection\n",
        "  source_cnx.close()"
      ],
      "metadata": {
        "id": "m_hmoLcp7upe"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datawarehouse Creation "
      ],
      "metadata": {
        "id": "-dJQzeoh7y1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create Datawarehouse\n",
        "dwh_db = DB(DB_DWH_PATH)"
      ],
      "metadata": {
        "id": "cfzedVsf734C"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('starting etl')   \n",
        "# list for iteration\n",
        "etl_queue = []\n",
        "\n",
        "# patient table\n",
        "patients_columns = ['Id', 'BIRTHDATE', 'DEATHDATE', 'GENDER']\n",
        "sql_query_patients = SqlQuery(\"patients\", patients_columns, \"patients_info\")\n",
        "etl_queue.append(sql_query_patients)\n",
        "\n",
        "# symptoms and procedures table\n",
        "conditions_columns = ['START', 'STOP', 'PATIENT', 'CODE', 'DESCRIPTION']\n",
        "sql_query_conditions = SqlQuery(\"conditions\", conditions_columns, \"conditions_info\")\n",
        "etl_queue.append(sql_query_conditions)\n",
        "\n",
        "# procedures table\n",
        "procedures_columns = ['DATE', 'PATIENT', 'CODE', 'DESCRIPTION']\n",
        "sql_query_procedures = SqlQuery(\"procedures\", procedures_columns, \"procedures_info\")\n",
        "etl_queue.append(sql_query_procedures)\n",
        "\n",
        "# devices table\n",
        "devices_columns = ['START', 'STOP', 'PATIENT', 'CODE', 'DESCRIPTION']\n",
        "sql_query_devices = SqlQuery(\"devices\", devices_columns, \"devices_info\")\n",
        "etl_queue.append(sql_query_devices)\n",
        "\n",
        "# medications table\n",
        "medications_columns = ['START', 'STOP', 'PATIENT', 'CODE', 'DESCRIPTION']\n",
        "sql_query_medications = SqlQuery(\"medications\", medications_columns, \"medications_info\")\n",
        "etl_queue.append(sql_query_medications)\n",
        "\n",
        "# immunizations table\n",
        "immunizations_columns = ['DATE', 'ENCOUNTER', 'PATIENT', 'CODE','DESCRIPTION']\n",
        "sql_query_immunizations = SqlQuery(\"immunizations\", immunizations_columns, \"immunizations_info\")\n",
        "etl_queue.append(sql_query_immunizations)\n",
        "\n",
        "# list for iteration\n",
        "etl_queue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPi7UX8y8AqC",
        "outputId": "f7735b11-bda4-44e5-c499-802516d6033c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting etl\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<__main__.SqlQuery at 0x7f62d0d470a0>,\n",
              " <__main__.SqlQuery at 0x7f62d0d472b0>,\n",
              " <__main__.SqlQuery at 0x7f62d0d47970>,\n",
              " <__main__.SqlQuery at 0x7f62d0d47340>,\n",
              " <__main__.SqlQuery at 0x7f62d0d47ac0>,\n",
              " <__main__.SqlQuery at 0x7f62cd41e100>]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# establish connection for target database (sql-server)\n",
        "target_cnx = dwh_db.conn\n",
        "etl_process(etl_queue, target_cnx, DB_SOURCE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWFZYGnW8EoW",
        "outputId": "8b3dbad7-c538-4b16-9237-7e46a438b881"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data loaded to warehouse db\n",
            "data loaded to warehouse db"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function DB.__del__ at 0x7f62d46ab310>\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-32-e422f2702e6e>\", line 8, in __del__\n",
            "sqlite3.ProgrammingError: SQLite objects created in a thread can only be used in that same thread. The object was created in thread id 140062728399936 and this is thread id 140062397892352.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "data loaded to warehouse db\n",
            "data loaded to warehouse db\n",
            "data loaded to warehouse db\n",
            "data loaded to warehouse db\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_cnx.commit()"
      ],
      "metadata": {
        "id": "Gb5RFlX48KFI"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#target_cnx.close()"
      ],
      "metadata": {
        "id": "fs6AMRTU8LLJ"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}